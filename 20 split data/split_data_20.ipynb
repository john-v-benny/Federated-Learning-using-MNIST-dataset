{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9663583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97133c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Original training data shape: (60000, 28, 28)\n",
      "Original training labels shape: (60000,)\n",
      "Original test data shape: (10000, 28, 28)\n",
      "Original test labels shape: (10000,)\n",
      "Data type: uint8\n",
      "Pixel value range: [0, 255]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Original training data shape: {x_train.shape}\")\n",
    "print(f\"Original training labels shape: {y_train.shape}\")\n",
    "print(f\"Original test data shape: {x_test.shape}\")\n",
    "print(f\"Original test labels shape: {y_test.shape}\")\n",
    "print(f\"Data type: {x_train.dtype}\")\n",
    "print(f\"Pixel value range: [{x_train.min()}, {x_train.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996df80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1] range\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35166524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (70000, 28, 28)\n",
      "Combined labels shape: (70000,)\n",
      "Data shuffled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Combine training and test data for balanced splitting\n",
    "x_combined = np.concatenate([x_train_norm, x_test_norm], axis=0)\n",
    "y_combined = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "print(f\"Combined data shape: {x_combined.shape}\")\n",
    "print(f\"Combined labels shape: {y_combined.shape}\")\n",
    "\n",
    "# Shuffle the combined data\n",
    "from sklearn.utils import shuffle\n",
    "x_combined, y_combined = shuffle(x_combined, y_combined, random_state=42)\n",
    "print(\"Data shuffled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdba637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 total samples: 3500\n",
      "Part 2 total samples: 3500\n",
      "Part 3 total samples: 3500\n",
      "Part 4 total samples: 3500\n",
      "Part 5 total samples: 3500\n",
      "Part 6 total samples: 3500\n",
      "Part 7 total samples: 3500\n",
      "Part 8 total samples: 3500\n",
      "Part 9 total samples: 3500\n",
      "Part 10 total samples: 3500\n",
      "Part 11 total samples: 3500\n",
      "Part 12 total samples: 3500\n",
      "Part 13 total samples: 3500\n",
      "Part 14 total samples: 3500\n",
      "Part 15 total samples: 3500\n",
      "Part 16 total samples: 3500\n",
      "Part 17 total samples: 3500\n",
      "Part 18 total samples: 3500\n",
      "Part 19 total samples: 3500\n",
      "Part 20 total samples: 3500\n",
      "Covered: 70000 of 70000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Five equal, disjoint, stratified parts\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "parts_x, parts_y, fold_indices = [], [], []\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(x_combined, y_combined), start=1):\n",
    "    parts_x.append(x_combined[test_idx])\n",
    "    parts_y.append(y_combined[test_idx])\n",
    "    fold_indices.append(test_idx)\n",
    "    print(f\"Part {fold} total samples: {parts_x[-1].shape[0]}\")\n",
    "\n",
    "# Optional: assign to named variables if you prefer\n",
    "x_part1_all, y_part1_all = parts_x[0], parts_y[0]\n",
    "x_part2_all, y_part2_all = parts_x[1], parts_y[1]\n",
    "x_part3_all, y_part3_all = parts_x[2], parts_y[2]\n",
    "x_part4_all, y_part4_all = parts_x[3], parts_y[3]\n",
    "x_part5_all, y_part5_all = parts_x[4], parts_y[4]\n",
    "x_part6_all, y_part6_all = parts_x[5], parts_y[5]\n",
    "x_part7_all, y_part7_all = parts_x[6], parts_y[6]\n",
    "x_part8_all, y_part8_all = parts_x[7], parts_y[7]\n",
    "x_part9_all, y_part9_all = parts_x[8], parts_y[8]\n",
    "x_part10_all, y_part10_all = parts_x[9], parts_y[9]\n",
    "x_part11_all, y_part11_all = parts_x[10], parts_y[10]\n",
    "x_part12_all, y_part12_all = parts_x[11], parts_y[11]\n",
    "x_part13_all, y_part13_all = parts_x[12], parts_y[12]\n",
    "x_part14_all, y_part14_all = parts_x[13], parts_y[13]\n",
    "x_part15_all, y_part15_all = parts_x[14], parts_y[14]\n",
    "x_part16_all, y_part16_all = parts_x[15], parts_y[15]\n",
    "x_part17_all, y_part17_all = parts_x[16], parts_y[16]\n",
    "x_part18_all, y_part18_all = parts_x[17], parts_y[17]\n",
    "x_part19_all, y_part19_all = parts_x[18], parts_y[18]\n",
    "x_part20_all, y_part20_all = parts_x[19], parts_y[19]\n",
    "\n",
    "# Sanity check (coverage and no overlap)\n",
    "concat_idx = np.concatenate(fold_indices)\n",
    "print(f\"Covered: {np.unique(concat_idx).size} of {x_combined.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4d7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: train=2999, test=501\n",
      "Part 2: train=2999, test=501\n",
      "Part 3: train=2999, test=501\n",
      "Part 4: train=2999, test=501\n",
      "Part 5: train=2999, test=501\n",
      "Part 6: train=2999, test=501\n",
      "Part 7: train=2999, test=501\n",
      "Part 8: train=2999, test=501\n",
      "Part 9: train=2999, test=501\n",
      "Part 10: train=2999, test=501\n",
      "Part 11: train=2999, test=501\n",
      "Part 12: train=2999, test=501\n",
      "Part 13: train=2999, test=501\n",
      "Part 14: train=2999, test=501\n",
      "Part 15: train=2999, test=501\n",
      "Part 16: train=2999, test=501\n",
      "Part 17: train=2999, test=501\n",
      "Part 18: train=2999, test=501\n",
      "Part 19: train=2999, test=501\n",
      "Part 20: train=2999, test=501\n"
     ]
    }
   ],
   "source": [
    "original_train_ratio = 60000 / (60000 + 10000)\n",
    "test_ratio = 1 - original_train_ratio  # ~0.142857\n",
    "\n",
    "x_parts_train, x_parts_test, y_parts_train, y_parts_test = [], [], [], []\n",
    "\n",
    "for i, (px, py) in enumerate(zip(parts_x, parts_y), start=1):\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "        px, py,\n",
    "        test_size=test_ratio,\n",
    "        stratify=py,\n",
    "        random_state=42  # keep reproducible\n",
    "    )\n",
    "    x_parts_train.append(x_tr); x_parts_test.append(x_te)\n",
    "    y_parts_train.append(y_tr); y_parts_test.append(y_te)\n",
    "    print(f\"Part {i}: train={x_tr.shape[0]}, test={x_te.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d90784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part 1 to mnist_split_data_20\\mnist_part1.npz (0.88 MB)\n",
      "Saved Part 2 to mnist_split_data_20\\mnist_part2.npz (0.88 MB)\n",
      "Saved Part 3 to mnist_split_data_20\\mnist_part3.npz (0.88 MB)\n",
      "Saved Part 4 to mnist_split_data_20\\mnist_part4.npz (0.88 MB)\n",
      "Saved Part 5 to mnist_split_data_20\\mnist_part5.npz (0.88 MB)\n",
      "Saved Part 6 to mnist_split_data_20\\mnist_part6.npz (0.88 MB)\n",
      "Saved Part 7 to mnist_split_data_20\\mnist_part7.npz (0.88 MB)\n",
      "Saved Part 8 to mnist_split_data_20\\mnist_part8.npz (0.88 MB)\n",
      "Saved Part 9 to mnist_split_data_20\\mnist_part9.npz (0.88 MB)\n",
      "Saved Part 10 to mnist_split_data_20\\mnist_part10.npz (0.88 MB)\n",
      "Saved Part 11 to mnist_split_data_20\\mnist_part11.npz (0.88 MB)\n",
      "Saved Part 12 to mnist_split_data_20\\mnist_part12.npz (0.88 MB)\n",
      "Saved Part 13 to mnist_split_data_20\\mnist_part13.npz (0.88 MB)\n",
      "Saved Part 14 to mnist_split_data_20\\mnist_part14.npz (0.88 MB)\n",
      "Saved Part 15 to mnist_split_data_20\\mnist_part15.npz (0.88 MB)\n",
      "Saved Part 16 to mnist_split_data_20\\mnist_part16.npz (0.88 MB)\n",
      "Saved Part 17 to mnist_split_data_20\\mnist_part17.npz (0.88 MB)\n",
      "Saved Part 18 to mnist_split_data_20\\mnist_part18.npz (0.88 MB)\n",
      "Saved Part 19 to mnist_split_data_20\\mnist_part19.npz (0.88 MB)\n",
      "Saved Part 20 to mnist_split_data_20\\mnist_part20.npz (0.88 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = \"mnist_split_data_20\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i in range(20):\n",
    "    out_path = os.path.join(save_dir, f\"mnist_part{i+1}.npz\")\n",
    "    np.savez_compressed(\n",
    "        out_path,\n",
    "        x_train=x_parts_train[i],\n",
    "        y_train=y_parts_train[i],\n",
    "        x_test=x_parts_test[i],\n",
    "        y_test=y_parts_test[i],\n",
    "    )\n",
    "    size_mb = os.path.getsize(out_path) / (1024*1024)\n",
    "    print(f\"Saved Part {i+1} to {out_path} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5031be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
