{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 6\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part6.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206a79ba290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m100,480\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m330\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3209 - loss: 2.0794 - val_accuracy: 0.0800 - val_loss: 2.3255\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5813 - loss: 1.2838 - val_accuracy: 0.1367 - val_loss: 2.3678\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 1.0082 - val_accuracy: 0.1367 - val_loss: 2.4158\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.8590 - val_accuracy: 0.1500 - val_loss: 2.4478\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.7618 - val_accuracy: 0.1600 - val_loss: 2.4466\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.6771 - val_accuracy: 0.1733 - val_loss: 2.4105\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.6159 - val_accuracy: 0.2033 - val_loss: 2.3331\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.5907 - val_accuracy: 0.2033 - val_loss: 2.2122\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8540 - loss: 0.5220 - val_accuracy: 0.3267 - val_loss: 2.0202\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.4917 - val_accuracy: 0.3767 - val_loss: 1.8116\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.4777 - val_accuracy: 0.5900 - val_loss: 1.4930\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.4534 - val_accuracy: 0.7267 - val_loss: 1.1908\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.4121 - val_accuracy: 0.8533 - val_loss: 0.8162\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.4205 - val_accuracy: 0.8633 - val_loss: 0.6682\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3766 - val_accuracy: 0.9233 - val_loss: 0.4416\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3738 - val_accuracy: 0.9067 - val_loss: 0.4097\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.3557 - val_accuracy: 0.9300 - val_loss: 0.3185\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3424 - val_accuracy: 0.9200 - val_loss: 0.3143\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.3372 - val_accuracy: 0.9200 - val_loss: 0.2878\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.3247 - val_accuracy: 0.8800 - val_loss: 0.3516\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.3049 - val_accuracy: 0.9200 - val_loss: 0.2519\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2948 - val_accuracy: 0.9133 - val_loss: 0.2886\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2864 - val_accuracy: 0.9300 - val_loss: 0.2573\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2773 - val_accuracy: 0.9067 - val_loss: 0.2867\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2715 - val_accuracy: 0.8900 - val_loss: 0.3188\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2538 - val_accuracy: 0.9133 - val_loss: 0.2615\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2717 - val_accuracy: 0.9233 - val_loss: 0.2529\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.2531 - val_accuracy: 0.9267 - val_loss: 0.2264\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2363 - val_accuracy: 0.9067 - val_loss: 0.3040\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2415 - val_accuracy: 0.9267 - val_loss: 0.2311\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.8842 - loss: 0.3740\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ Training Accuracy: 92.37%\n",
      "ğŸ¯ Test Accuracy:     88.42%\n",
      "   Difference:        3.94%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ¯ Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ¯ Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v6.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
