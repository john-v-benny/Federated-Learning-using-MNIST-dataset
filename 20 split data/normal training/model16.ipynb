{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 16\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part16.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1f0b33210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3275 - loss: 2.0140 - val_accuracy: 0.1067 - val_loss: 2.3073\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 1.2765 - val_accuracy: 0.1067 - val_loss: 2.3363\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.9864 - val_accuracy: 0.1067 - val_loss: 2.3712\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.8413 - val_accuracy: 0.1067 - val_loss: 2.3933\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.7269 - val_accuracy: 0.1067 - val_loss: 2.3999\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.6625 - val_accuracy: 0.1067 - val_loss: 2.3946\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.6051 - val_accuracy: 0.1067 - val_loss: 2.3348\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.5379 - val_accuracy: 0.1067 - val_loss: 2.2179\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.5146 - val_accuracy: 0.1067 - val_loss: 2.1017\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.4707 - val_accuracy: 0.1600 - val_loss: 1.8964\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.4539 - val_accuracy: 0.3667 - val_loss: 1.6110\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.4461 - val_accuracy: 0.5433 - val_loss: 1.3264\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.4071 - val_accuracy: 0.6967 - val_loss: 1.0319\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.4145 - val_accuracy: 0.7833 - val_loss: 0.7839\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.3571 - val_accuracy: 0.8700 - val_loss: 0.5185\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3604 - val_accuracy: 0.8800 - val_loss: 0.4614\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.3464 - val_accuracy: 0.8767 - val_loss: 0.4622\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.3433 - val_accuracy: 0.8867 - val_loss: 0.3963\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.3498 - val_accuracy: 0.9000 - val_loss: 0.3622\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.3099 - val_accuracy: 0.9000 - val_loss: 0.3222\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.3027 - val_accuracy: 0.9100 - val_loss: 0.3035\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.3123 - val_accuracy: 0.9100 - val_loss: 0.3271\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2929 - val_accuracy: 0.9100 - val_loss: 0.3227\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2748 - val_accuracy: 0.9033 - val_loss: 0.3364\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2605 - val_accuracy: 0.9167 - val_loss: 0.2995\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.2523 - val_accuracy: 0.8933 - val_loss: 0.3151\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.2445 - val_accuracy: 0.8933 - val_loss: 0.3266\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.2331 - val_accuracy: 0.9067 - val_loss: 0.2916\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.2325 - val_accuracy: 0.9167 - val_loss: 0.2647\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.2430 - val_accuracy: 0.9000 - val_loss: 0.3040\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.9142 - loss: 0.3135\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 92.66%\n",
      "🎯 Test Accuracy:     91.42%\n",
      "   Difference:        1.25%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v16.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
