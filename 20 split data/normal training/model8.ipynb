{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 8\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part8.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15d668ec950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3572 - loss: 1.9180 - val_accuracy: 0.1133 - val_loss: 2.2977\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5999 - loss: 1.2442 - val_accuracy: 0.1133 - val_loss: 2.3019\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 1.0025 - val_accuracy: 0.1133 - val_loss: 2.3218\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.8782 - val_accuracy: 0.1133 - val_loss: 2.3282\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.7444 - val_accuracy: 0.1133 - val_loss: 2.3270\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.6722 - val_accuracy: 0.1133 - val_loss: 2.3082\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.5982 - val_accuracy: 0.1133 - val_loss: 2.2476\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.5695 - val_accuracy: 0.1133 - val_loss: 2.1631\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.5046 - val_accuracy: 0.1833 - val_loss: 1.9753\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.4766 - val_accuracy: 0.3367 - val_loss: 1.7379\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.4591 - val_accuracy: 0.4633 - val_loss: 1.5034\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.4435 - val_accuracy: 0.6533 - val_loss: 1.1683\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.4184 - val_accuracy: 0.7400 - val_loss: 0.9129\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3942 - val_accuracy: 0.7933 - val_loss: 0.7262\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.3538 - val_accuracy: 0.8800 - val_loss: 0.4913\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.3573 - val_accuracy: 0.8700 - val_loss: 0.4178\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.3430 - val_accuracy: 0.8633 - val_loss: 0.4265\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3290 - val_accuracy: 0.9000 - val_loss: 0.3296\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2931 - val_accuracy: 0.8800 - val_loss: 0.3437\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.3074 - val_accuracy: 0.9033 - val_loss: 0.2952\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2956 - val_accuracy: 0.9167 - val_loss: 0.3257\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2715 - val_accuracy: 0.9133 - val_loss: 0.2801\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2645 - val_accuracy: 0.8900 - val_loss: 0.3256\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.2537 - val_accuracy: 0.9067 - val_loss: 0.3032\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2649 - val_accuracy: 0.9167 - val_loss: 0.2754\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.2524 - val_accuracy: 0.9167 - val_loss: 0.2656\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2458 - val_accuracy: 0.8867 - val_loss: 0.3038\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.2239 - val_accuracy: 0.9167 - val_loss: 0.2663\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.2412 - val_accuracy: 0.9100 - val_loss: 0.2922\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.2127 - val_accuracy: 0.8933 - val_loss: 0.3050\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 3ms/step - accuracy: 0.8802 - loss: 0.3742\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.81%\n",
      "🎯 Test Accuracy:     88.02%\n",
      "   Difference:        5.79%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v8.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
