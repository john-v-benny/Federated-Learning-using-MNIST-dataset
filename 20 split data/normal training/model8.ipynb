{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 8\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part8.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1daff5ddbd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3416 - loss: 2.0055 - val_accuracy: 0.0867 - val_loss: 2.3062\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 1.2588 - val_accuracy: 0.0867 - val_loss: 2.3219\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 1.0041 - val_accuracy: 0.0867 - val_loss: 2.3447\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.8521 - val_accuracy: 0.0867 - val_loss: 2.3574\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.7605 - val_accuracy: 0.1000 - val_loss: 2.3519\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.6739 - val_accuracy: 0.1500 - val_loss: 2.3108\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.6291 - val_accuracy: 0.2567 - val_loss: 2.2371\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.5848 - val_accuracy: 0.3367 - val_loss: 2.1231\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.5311 - val_accuracy: 0.4033 - val_loss: 1.9642\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.4866 - val_accuracy: 0.5000 - val_loss: 1.7494\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.4742 - val_accuracy: 0.6433 - val_loss: 1.4764\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.4540 - val_accuracy: 0.7033 - val_loss: 1.2115\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.4312 - val_accuracy: 0.8000 - val_loss: 0.9155\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.3999 - val_accuracy: 0.8433 - val_loss: 0.6746\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.3972 - val_accuracy: 0.8633 - val_loss: 0.5462\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.3702 - val_accuracy: 0.8567 - val_loss: 0.5176\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.3538 - val_accuracy: 0.8833 - val_loss: 0.4094\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.3404 - val_accuracy: 0.8867 - val_loss: 0.3850\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.3219 - val_accuracy: 0.8667 - val_loss: 0.4003\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3205 - val_accuracy: 0.8800 - val_loss: 0.3752\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.3007 - val_accuracy: 0.8833 - val_loss: 0.3478\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2909 - val_accuracy: 0.8800 - val_loss: 0.3847\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.3068 - val_accuracy: 0.8867 - val_loss: 0.3674\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.2897 - val_accuracy: 0.8800 - val_loss: 0.3962\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2775 - val_accuracy: 0.8867 - val_loss: 0.3833\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2556 - val_accuracy: 0.8900 - val_loss: 0.3544\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2580 - val_accuracy: 0.8767 - val_loss: 0.3753\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2478 - val_accuracy: 0.8767 - val_loss: 0.3695\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2540 - val_accuracy: 0.8733 - val_loss: 0.3968\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.2242 - val_accuracy: 0.8567 - val_loss: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 4ms/step - accuracy: 0.8822 - loss: 0.4181\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.81%\n",
      "🎯 Test Accuracy:     88.22%\n",
      "   Difference:        5.59%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v8.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
