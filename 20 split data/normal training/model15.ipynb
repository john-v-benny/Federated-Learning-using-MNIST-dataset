{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 15\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part15.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ce4d86d090>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGkCAYAAACckEpMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGcZJREFUeJzt3X2QldWdJ/Bfg9Cg0o2I0BAaBF8TBbLxBVlfgoECTa0jyh8azQykKCgIOkFidEmpqEltJ6bKOGYI/mNEd32LtSKjM0NKUaCIoCvKMMaECEMClICRHWjAgEg/W8/jdmMrmty229Pd9/OpOty+9z6nn8Ph4X7veZ5zz63IsiwLAEioS8qdA0BOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQXIcJo/nz58eJJ54YPXr0iFGjRsXLL78c5eb222+PioqKZuX000+PcrBixYq47LLLYuDAgcXf+6mnnmr2fL6q1W233RYDBgyInj17xrhx4+LNN9+McuuHKVOmfOwYueSSS6Kzqauri3POOSd69eoV/fr1i4kTJ8b69eubbbN///6YNWtWHH/88XHsscfGpEmTYseOHVFu/TBmzJiPHRMzZsyI9qZDhNHjjz8ec+bMiXnz5sWrr74aI0eOjAkTJsTbb78d5eaMM86Ibdu2NZWVK1dGOdi3b1/x756/KTmSu+66K+69996477774qWXXopjjjmmOEbyF6Ry6odcHj4fPkYeffTR6GyWL19eBM3q1avj2WefjYMHD8b48eOL/ml0ww03xNNPPx1PPPFEsf1bb70VV155ZZRbP+SmTZvW7JjI/7+0O1kHcO6552azZs1qun/o0KFs4MCBWV1dXVZO5s2bl40cOTIrd/lhu2jRoqb7DQ0NWU1NTfaTn/yk6bFdu3ZllZWV2aOPPpqVSz/kJk+enF1++eVZuXn77beL/li+fHnTv3+3bt2yJ554ommb3/72t8U2q1atysqlH3Jf/epXs+985ztZe9fuR0bvvfderFmzpjjt0qhLly7F/VWrVkW5yU895adohg0bFtdee21s3rw5yt2mTZti+/btzY6R6urq4nRuOR4jy5YtK07ZnHbaaTFz5szYuXNndHa7d+8ubvv06VPc5q8Z+Sjhw8dEfkp78ODBnfqY2P2Rfmj08MMPR9++fePMM8+MuXPnxrvvvhvtzVHRzr3zzjtx6NCh6N+/f7PH8/u/+93vopzkL64LFy4sXmTyofYdd9wRF154Ybz++uvFOeNylQdR7kjHSONz5SI/RZefiho6dGhs3Lgxvv/978ell15avAB37do1OqOGhoaYPXt2nH/++cWLbS7/d+/evXv07t27bI6JhiP0Q+6aa66JIUOGFG9i161bFzfffHNxXenJJ5+M9qTdhxGH5S8qjUaMGFGEU36Q/fKXv4ypU6cmbRvtw9VXX9308/Dhw4vj5KSTTipGS2PHjo3OKL9mkr8hK5frp6X2w/Tp05sdE/kkn/xYyN+s5MdGe9HuT9PlQ8v8Hd1HZ8Hk92tqaqKc5e/6Tj311NiwYUOUs8bjwDHycfnp3Pz/UGc9Rq677rp45pln4oUXXohBgwY1PZ7/u+en+Hft2lUWx8R1n9APR5K/ic21t2Oi3YdRPtQ+66yzYunSpc2Go/n90aNHRznbu3dv8e4mf6dTzvJTUvkLzIePkfr6+mJWXbkfI1u3bi2uGXW2YySfv5G/AC9atCief/754hj4sPw1o1u3bs2OifzUVH6NtTMdE9lf6IcjWbt2bXHb7o6JrAN47LHHiplRCxcuzN54441s+vTpWe/evbPt27dn5eS73/1utmzZsmzTpk3Zr3/962zcuHFZ3759ixk0nd2ePXuy1157rSj5YXv33XcXP//xj38snv/Rj35UHBOLFy/O1q1bV8woGzp0aPbnP/85K5d+yJ+78cYbi9li+THy3HPPZV/5yleyU045Jdu/f3/WmcycOTOrrq4u/j9s27atqbz77rtN28yYMSMbPHhw9vzzz2evvPJKNnr06KKUUz9s2LAhu/POO4u/f35M5P8/hg0bll100UVZe9Mhwij3s5/9rDiwunfvXkz1Xr16dVZurrrqqmzAgAFFH3zhC18o7ucHWzl44YUXihffj5Z8KnPj9O5bb70169+/f/HGZezYsdn69euzcuqH/AVo/Pjx2QknnFBMax4yZEg2bdq0Tvmm7Uh9kJcHHnigaZv8jci3v/3t7LjjjsuOPvro7IorriheqMupHzZv3lwET58+fYr/FyeffHL2ve99L9u9e3fW3lTkf6QenQFQ3tr9NSMAOj9hBEBywgiA5IQRAMkJIwCSE0YAJNehwujAgQPFF8zlt+VMPxymLz6gHw7TFx2zHzrU54zyJV7yrwbIl0mvqqqKcqUfDtMXH9APh+mLjtkPHWpkBEDnJIwASK7dfZ9RviJ3/l31+ZfFVVRUfGzY+eHbcqUfDtMXH9APh+mL9tMP+VWgPXv2FF/sl39Dd4e6ZpQveV9bW5u6GQC0ki1btvzF71lqdyOjxq/PviC+HkdFt9TNAaCF3o+DsTL+pel1vUOFUeOpuTyIjqoQRgAd1v8/7/bRSy6f6wSG+fPnx4knnhg9evQovub25ZdfbqtdAdDBtUkYPf744zFnzpyYN29evPrqqzFy5MiYMGFCvP32222xOwA6uDYJo7vvvjumTZsW3/rWt+JLX/pS3HfffXH00UfHL37xi7bYHQAdXKuH0XvvvRdr1qyJcePGHd5Jly7F/VWrVn1s+3ypinzq4YcLAOWl1cPonXfeiUOHDkX//v2bPZ7f3759+8e2r6urK5asaCymdQOUn+QrMMydO7dYO6mx5PPRASgvrT61u2/fvtG1a9fYsWNHs8fz+zU1NR/bvrKysigAlK9WHxl17949zjrrrFi6dGmzJX7y+6NHj27t3QHQCbTJh17zad2TJ0+Os88+O84999y45557Yt++fcXsOgD4XMLoqquuij/96U9x2223FZMWvvzlL8eSJUs+NqkBANrlQqmNXwg1Ji63HBBAB/Z+djCWxeK/6gv+ks+mAwBhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAOh8YXT77bdHRUVFs3L66ae39m4A6ESOaotfesYZZ8Rzzz13eCdHtcluAOgk2iQl8vCpqalpi18NQCfUJteM3nzzzRg4cGAMGzYsrr322ti8efMnbnvgwIGor69vVgAoL60eRqNGjYqFCxfGkiVLYsGCBbFp06a48MILY8+ePUfcvq6uLqqrq5tKbW1tazcJgHauIsuyrC13sGvXrhgyZEjcfffdMXXq1COOjPLSKB8Z5YE0Ji6Poyq6tWXTAGhD72cHY1ksjt27d0dVVdWnbtvmMwt69+4dp556amzYsOGIz1dWVhYFgPLV5p8z2rt3b2zcuDEGDBjQ1rsCoINq9TC68cYbY/ny5fGHP/whXnzxxbjiiiuia9eu8Y1vfKO1dwVAJ9Hqp+m2bt1aBM/OnTvjhBNOiAsuuCBWr15d/AwAn0sYPfbYY639KwHo5CyNQIs1XPhfWlRvwF0bS67zb4+dWXKdmn94seQ6QBoWSgUgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyVkolQ+cN6LkKrc/eH+LdnV25aGS6+y58V9LrrN4xkkl1+la0RAtcSgr/X3dT564ouQ6x/0uK7lOZ1X1yOrUTaAVGRkBkJwwAiA5YQRAcsIIgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOQslErh99O7fy4LnrZUry6lt++bVVtKrtOlhe/PGqL0BVa/OfXe+Ly05O/Vkr/T52n4iL8vuc6wea+WXCc7cKDkOpTOyAiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEjOqt1Ah/Sbv/3Hkuv8zaPfLLlO9m+/LbkOpTMyAiA5YQRAcsIIgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOSEEQDJWSiVDuHM5dNKrjPsmrVt0paOaMut/7XkOq/N+Idoz/7HO8NLrtNlZ33JdRpKrkFLGBkBkJwwAqDjhdGKFSvisssui4EDB0ZFRUU89dRTzZ7Psixuu+22GDBgQPTs2TPGjRsXb775Zmu2GYByD6N9+/bFyJEjY/78+Ud8/q677op777037rvvvnjppZfimGOOiQkTJsT+/ftbo70AdEIlT2C49NJLi3Ik+ajonnvuiVtuuSUuv/zy4rGHHnoo+vfvX4ygrr766s/eYgA6nVa9ZrRp06bYvn17cWquUXV1dYwaNSpWrVp1xDoHDhyI+vr6ZgWA8tKqYZQHUS4fCX1Yfr/xuY+qq6srAqux1NbWtmaTAOgAks+mmzt3buzevbupbNmyJXWTAOjIYVRTU1Pc7tixo9nj+f3G5z6qsrIyqqqqmhUAykurhtHQoUOL0Fm6dGnTY/k1oHxW3ejRo1tzVwCU82y6vXv3xoYNG5pNWli7dm306dMnBg8eHLNnz44f/vCHccoppxThdOuttxafSZo4cWJrtx2Acg2jV155JS6++OKm+3PmzCluJ0+eHAsXLoybbrqp+CzS9OnTY9euXXHBBRfEkiVLokePHq3bcgDKN4zGjBlTfJ7ok+SrMtx5551FIY2uZ5xWcp3FX/vHluwpPi8n/JM3M5/FL771s+hsfvnYmJLrDNr6Ypu0hU4wmw4AhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyQkjAJITRgB0vIVS6ZwasorUTeCvcFTtoBbVO6tyTcl1Glqwn90N75Vc57ynPlj5v1Sn1Fn0tDMxMgIgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyQkjAJKzancndOg360uu8/ezry+5zrM/nx8tce9/nl5ynd7r/m/JdQ5F51uB+9xn/iPas5aswH3K9S+1SVvoWIyMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEByFkql0POf/k/Jdab997Et2tfbf+5Vcp3sjd9HZ1PxP0tfyvX7ff+9RfvqVtG15DoHs9L30//FitIrgZERAO2BMAIgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkLJTKB7LSV8V8528qW7Srrr26lVzn/eh8GrLSFxVtiIYW7asli55O/sO4kusc989vlFyn9OVi6YyMjABIThgB0PHCaMWKFXHZZZfFwIEDo6KiIp566qlmz0+ZMqV4/MPlkksuac02A1DuYbRv374YOXJkzJ8//xO3ycNn27ZtTeXRRx/9rO0EoBMreQLDpZdeWpRPU1lZGTU1NZ+lXQCUkTa5ZrRs2bLo169fnHbaaTFz5szYuXPnJ2574MCBqK+vb1YAKC+tHkb5KbqHHnooli5dGj/+8Y9j+fLlxUjq0KEjT+Csq6uL6urqplJbW9vaTQKg3D5ndPXVVzf9PHz48BgxYkScdNJJxWhp7NixH9t+7ty5MWfOnKb7+chIIAGUlzaf2j1s2LDo27dvbNiw4ROvL1VVVTUrAJSXNg+jrVu3FteMBgwY0Na7AqBcTtPt3bu32Shn06ZNsXbt2ujTp09R7rjjjpg0aVIxm27jxo1x0003xcknnxwTJkxo7bYDUK5h9Morr8TFF1/cdL/xes/kyZNjwYIFsW7dunjwwQdj165dxQdjx48fHz/4wQ+K03EA0CphNGbMmMg+ZVHNX/3qV6X+SgDKnFW7abFDf/pTyyq2tB6fq537jym9Uv3WtmgKZcBCqQAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOQulQms4b0TJVf5u4NPRnm3758El1xkQFkqlZYyMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEByFkqF1rB6XclV/te280quM+mUZ6IlulV0LbnOF5b+Z8l1GkquAR8wMgIgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyVkoFRJpyCpKr9PCpUgPZi2qBp8bIyMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5q3YDR/S7mb1KrnPqjDZpCmXAyAiA5IQRAB0rjOrq6uKcc86JXr16Rb9+/WLixImxfv36Ztvs378/Zs2aFccff3wce+yxMWnSpNixY0drtxuAcg2j5cuXF0GzevXqePbZZ+PgwYMxfvz42LdvX9M2N9xwQzz99NPxxBNPFNu/9dZbceWVV7ZF2wEoxwkMS5YsaXZ/4cKFxQhpzZo1cdFFF8Xu3bvj/vvvj0ceeSS+9rWvFds88MAD8cUvfrEIsPPOO+9jv/PAgQNFaVRfX9/yvw0A5XfNKA+fXJ8+fYrbPJTy0dK4ceOatjn99NNj8ODBsWrVqk889VddXd1UamtrP0uTACinMGpoaIjZs2fH+eefH2eeeWbx2Pbt26N79+7Ru3fvZtv279+/eO5I5s6dW4RaY9myZUtLmwRAuX3OKL929Prrr8fKlSs/UwMqKyuLAkD5atHI6LrrrotnnnkmXnjhhRg0aFDT4zU1NfHee+/Frl27mm2fz6bLnwOAzxxGWZYVQbRo0aJ4/vnnY+jQoc2eP+uss6Jbt26xdOnSpsfyqd+bN2+O0aNHl7IrAMrIUaWemstnyi1evLj4rFHjdaB84kHPnj2L26lTp8acOXOKSQ1VVVVx/fXXF0F0pJl0AFByGC1YsKC4HTNmTLPH8+nbU6ZMKX7+6U9/Gl26dCk+7JpP2Z4wYUL8/Oc/19sAtE4Y5afp/pIePXrE/PnziwJ0XKee8lbqJlBGrE0HQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkhBEAyQkjADruN70Cn02Xiqz0Oi18/9itomvJdSb0f6PkOs996eyS6xx64/cl16HzMTICIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSs2o3JHLglv4l1/nf9/dt0b4mHftOyXVmHbe+5Do//9aEkuuc8Np50RJV//Fu6ZVWr2vRvmh7RkYAJCeMAEhOGAGQnDACIDlhBEBywgiA5IQRAMkJIwCSE0YAJCeMAEhOGAGQnDACIDkLpUIiXVauLbnOA3/731q0r9rHHiy5ztmVpe/nN9fcW3qla6JFTv/VzJLrnLq6Zfui7RkZAZCcMAIgOWEEQHLCCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgOWEEQHLCCIDkLJQKHcnL/96iardPnlp6nQfvL7nO2ZWHSq5zwWvXRkvULvZeujPxrwlAcsIIgI4VRnV1dXHOOedEr169ol+/fjFx4sRYv359s23GjBkTFRUVzcqMGTNau90AlGsYLV++PGbNmhWrV6+OZ599Ng4ePBjjx4+Pffv2Ndtu2rRpsW3btqZy1113tXa7ASjXCQxLlixpdn/hwoXFCGnNmjVx0UUXNT1+9NFHR01NTeu1EoBO7TNdM9q9e3dx26dPn2aPP/zww9G3b98488wzY+7cufHuu+9+4u84cOBA1NfXNysAlJcWT+1uaGiI2bNnx/nnn1+ETqNrrrkmhgwZEgMHDox169bFzTffXFxXevLJJz/xOtQdd9zR0mYAUM5hlF87ev3112PlypXNHp8+fXrTz8OHD48BAwbE2LFjY+PGjXHSSSd97PfkI6c5c+Y03c9HRrW1tS1tFgDlEkbXXXddPPPMM7FixYoYNGjQp247atSo4nbDhg1HDKPKysqiAFC+SgqjLMvi+uuvj0WLFsWyZcti6NChf7HO2rVri9t8hAQAnzmM8lNzjzzySCxevLj4rNH27duLx6urq6Nnz57Fqbj8+a9//etx/PHHF9eMbrjhhmKm3YgRI0rZFQBlpKQwWrBgQdMHWz/sgQceiClTpkT37t3jueeei3vuuaf47FF+7WfSpElxyy23tG6rAehUKrL83Fs7kk9gyEdaY+LyOKqiW+rmANBC72cHY1ksLj4GVFVV9anbWpsOgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOSEEQDJCSMAkhNGACQnjABIThgBkJwwAiA5YQRAcsIIgOSOinYmy7Li9v04GPHBjwB0QMXr+Ide1ztUGO3Zs6e4XRn/kropALTS63p1dfWnblOR/TWR9TlqaGiIt956K3r16hUVFRXNnquvr4/a2trYsmVLVFVVRbnSD4fpiw/oh8P0Rfvphzxe8iAaOHBgdOnSpWONjPIGDxo06FO3yTu2nA+yRvrhMH3xAf1wmL5oH/3wl0ZEjUxgACA5YQRAch0qjCorK2PevHnFbTnTD4fpiw/oh8P0Rcfsh3Y3gQGA8tOhRkYAdE7CCIDkhBEAyQkjAJITRgAkJ4wASE4YAZCcMAIgUvt/KCUGQlziFrQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m100,480\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m330\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3701 - loss: 1.9463 - val_accuracy: 0.0833 - val_loss: 2.3151\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 1.1618 - val_accuracy: 0.0833 - val_loss: 2.3410\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.9518 - val_accuracy: 0.0833 - val_loss: 2.3623\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.7909 - val_accuracy: 0.1033 - val_loss: 2.3781\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.7126 - val_accuracy: 0.1633 - val_loss: 2.3646\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.6445 - val_accuracy: 0.1533 - val_loss: 2.3251\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.5812 - val_accuracy: 0.2100 - val_loss: 2.2344\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.5501 - val_accuracy: 0.2833 - val_loss: 2.1078\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.5167 - val_accuracy: 0.2667 - val_loss: 2.0223\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.4614 - val_accuracy: 0.4300 - val_loss: 1.7442\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.4319 - val_accuracy: 0.6000 - val_loss: 1.4901\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.4484 - val_accuracy: 0.7700 - val_loss: 1.1433\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.3938 - val_accuracy: 0.8067 - val_loss: 0.8855\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.4025 - val_accuracy: 0.8367 - val_loss: 0.6968\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.3582 - val_accuracy: 0.8267 - val_loss: 0.5782\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3679 - val_accuracy: 0.8533 - val_loss: 0.4871\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.3416 - val_accuracy: 0.8267 - val_loss: 0.4928\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3199 - val_accuracy: 0.8567 - val_loss: 0.4229\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.3146 - val_accuracy: 0.8733 - val_loss: 0.3898\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.3043 - val_accuracy: 0.9000 - val_loss: 0.3569\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2761 - val_accuracy: 0.8833 - val_loss: 0.3936\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2962 - val_accuracy: 0.8800 - val_loss: 0.4108\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2879 - val_accuracy: 0.8533 - val_loss: 0.3912\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2780 - val_accuracy: 0.8467 - val_loss: 0.4422\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2708 - val_accuracy: 0.8667 - val_loss: 0.3996\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2668 - val_accuracy: 0.8833 - val_loss: 0.3808\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2656 - val_accuracy: 0.8900 - val_loss: 0.3686\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2629 - val_accuracy: 0.8600 - val_loss: 0.4611\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2408 - val_accuracy: 0.8700 - val_loss: 0.4035\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2350 - val_accuracy: 0.8700 - val_loss: 0.4104\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 4ms/step - accuracy: 0.9182 - loss: 0.2967\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ Training Accuracy: 92.29%\n",
      "ğŸ¯ Test Accuracy:     91.82%\n",
      "   Difference:        0.48%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ¯ Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ¯ Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v15.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
