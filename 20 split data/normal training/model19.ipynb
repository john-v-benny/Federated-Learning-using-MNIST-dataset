{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 19\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part19.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x237c8e90b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2997 - loss: 2.1769 - val_accuracy: 0.0900 - val_loss: 2.3155\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.3185 - val_accuracy: 0.0900 - val_loss: 2.3569\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6517 - loss: 1.0665 - val_accuracy: 0.0900 - val_loss: 2.4080\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7155 - loss: 0.9343 - val_accuracy: 0.0900 - val_loss: 2.4374\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.8318 - val_accuracy: 0.0900 - val_loss: 2.4475\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.7420 - val_accuracy: 0.0900 - val_loss: 2.4292\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.6997 - val_accuracy: 0.1233 - val_loss: 2.3611\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.6073 - val_accuracy: 0.1867 - val_loss: 2.2555\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.5810 - val_accuracy: 0.2067 - val_loss: 2.1014\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.5346 - val_accuracy: 0.3300 - val_loss: 1.8830\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.5181 - val_accuracy: 0.4867 - val_loss: 1.6173\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8651 - loss: 0.4711 - val_accuracy: 0.6867 - val_loss: 1.2997\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.4768 - val_accuracy: 0.7967 - val_loss: 0.9847\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.4529 - val_accuracy: 0.8367 - val_loss: 0.7361\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.4140 - val_accuracy: 0.8767 - val_loss: 0.5172\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.4087 - val_accuracy: 0.8800 - val_loss: 0.4389\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.3820 - val_accuracy: 0.9067 - val_loss: 0.3972\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.3631 - val_accuracy: 0.8900 - val_loss: 0.3524\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3578 - val_accuracy: 0.8800 - val_loss: 0.3486\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3510 - val_accuracy: 0.9033 - val_loss: 0.3087\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.3397 - val_accuracy: 0.8900 - val_loss: 0.3089\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.3298 - val_accuracy: 0.9167 - val_loss: 0.2930\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.3031 - val_accuracy: 0.9033 - val_loss: 0.2809\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3159 - val_accuracy: 0.9133 - val_loss: 0.2965\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.3123 - val_accuracy: 0.8833 - val_loss: 0.3731\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2803 - val_accuracy: 0.9033 - val_loss: 0.3165\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2928 - val_accuracy: 0.9133 - val_loss: 0.2749\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2876 - val_accuracy: 0.8967 - val_loss: 0.3297\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2728 - val_accuracy: 0.9133 - val_loss: 0.2672\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2666 - val_accuracy: 0.8867 - val_loss: 0.3502\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.9002 - loss: 0.3484\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 91.81%\n",
      "🎯 Test Accuracy:     90.02%\n",
      "   Difference:        1.79%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v19.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
