{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 3\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part3.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ea4e33ebd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3361 - loss: 2.0455 - val_accuracy: 0.1267 - val_loss: 2.3049\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5787 - loss: 1.2663 - val_accuracy: 0.1267 - val_loss: 2.3281\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7043 - loss: 0.9784 - val_accuracy: 0.1267 - val_loss: 2.3590\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.8202 - val_accuracy: 0.1267 - val_loss: 2.3851\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.7501 - val_accuracy: 0.1267 - val_loss: 2.3954\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.6645 - val_accuracy: 0.1267 - val_loss: 2.3531\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.6072 - val_accuracy: 0.1367 - val_loss: 2.3129\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.5335 - val_accuracy: 0.2733 - val_loss: 2.2076\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8651 - loss: 0.5024 - val_accuracy: 0.3033 - val_loss: 2.0180\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.5001 - val_accuracy: 0.3600 - val_loss: 1.7813\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.4449 - val_accuracy: 0.4500 - val_loss: 1.5351\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.4446 - val_accuracy: 0.6700 - val_loss: 1.2001\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.4344 - val_accuracy: 0.7767 - val_loss: 0.9525\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8855 - loss: 0.3943 - val_accuracy: 0.8267 - val_loss: 0.7242\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.3715 - val_accuracy: 0.8900 - val_loss: 0.5316\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.3586 - val_accuracy: 0.8900 - val_loss: 0.4523\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3577 - val_accuracy: 0.9000 - val_loss: 0.4027\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.3353 - val_accuracy: 0.8900 - val_loss: 0.3852\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3219 - val_accuracy: 0.8900 - val_loss: 0.3410\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.3124 - val_accuracy: 0.9000 - val_loss: 0.3655\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3118 - val_accuracy: 0.8933 - val_loss: 0.3347\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2939 - val_accuracy: 0.9033 - val_loss: 0.3164\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2822 - val_accuracy: 0.8600 - val_loss: 0.4696\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2831 - val_accuracy: 0.8733 - val_loss: 0.3805\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2754 - val_accuracy: 0.8833 - val_loss: 0.3693\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2612 - val_accuracy: 0.8967 - val_loss: 0.3229\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2501 - val_accuracy: 0.9067 - val_loss: 0.3343\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2462 - val_accuracy: 0.8900 - val_loss: 0.3623\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.2277 - val_accuracy: 0.9033 - val_loss: 0.3176\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2211 - val_accuracy: 0.9000 - val_loss: 0.3236\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.9142 - loss: 0.2947\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.85%\n",
      "🎯 Test Accuracy:     91.42%\n",
      "   Difference:        2.43%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v3.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
