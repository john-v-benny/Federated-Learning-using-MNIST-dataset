{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 18\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part18.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f97f5f5910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m100,480\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m330\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3512 - loss: 1.9522 - val_accuracy: 0.1067 - val_loss: 2.3072\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 1.2487 - val_accuracy: 0.1067 - val_loss: 2.3238\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 1.0213 - val_accuracy: 0.1067 - val_loss: 2.3439\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.8564 - val_accuracy: 0.1067 - val_loss: 2.3605\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.7368 - val_accuracy: 0.1067 - val_loss: 2.3605\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.6852 - val_accuracy: 0.1067 - val_loss: 2.3498\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.6236 - val_accuracy: 0.1167 - val_loss: 2.3124\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.5751 - val_accuracy: 0.1333 - val_loss: 2.2311\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.5339 - val_accuracy: 0.1533 - val_loss: 2.1007\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.5092 - val_accuracy: 0.2233 - val_loss: 1.9053\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.4740 - val_accuracy: 0.3900 - val_loss: 1.6392\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.4633 - val_accuracy: 0.5367 - val_loss: 1.3653\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.4298 - val_accuracy: 0.7367 - val_loss: 1.0572\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.4099 - val_accuracy: 0.8500 - val_loss: 0.7589\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.3956 - val_accuracy: 0.8467 - val_loss: 0.5722\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.3561 - val_accuracy: 0.8633 - val_loss: 0.4686\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.3568 - val_accuracy: 0.8933 - val_loss: 0.4002\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3329 - val_accuracy: 0.8733 - val_loss: 0.3634\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3363 - val_accuracy: 0.8733 - val_loss: 0.3884\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.3193 - val_accuracy: 0.8667 - val_loss: 0.3789\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2968 - val_accuracy: 0.8900 - val_loss: 0.3978\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2990 - val_accuracy: 0.8767 - val_loss: 0.3354\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2833 - val_accuracy: 0.8733 - val_loss: 0.3294\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.2702 - val_accuracy: 0.8733 - val_loss: 0.3673\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2633 - val_accuracy: 0.8967 - val_loss: 0.3573\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2599 - val_accuracy: 0.8967 - val_loss: 0.3207\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2549 - val_accuracy: 0.8833 - val_loss: 0.3129\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2693 - val_accuracy: 0.8900 - val_loss: 0.3288\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.2439 - val_accuracy: 0.8700 - val_loss: 0.4166\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2366 - val_accuracy: 0.8833 - val_loss: 0.3876\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.9182 - loss: 0.2431\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ Training Accuracy: 92.33%\n",
      "ğŸ¯ Test Accuracy:     91.82%\n",
      "   Difference:        0.51%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ¯ Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ¯ Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v18.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
