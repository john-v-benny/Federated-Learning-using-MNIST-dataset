{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 11\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part11.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1727fd5d090>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3123 - loss: 2.0684 - val_accuracy: 0.1100 - val_loss: 2.3002\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 1.2770 - val_accuracy: 0.1100 - val_loss: 2.3145\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 1.0455 - val_accuracy: 0.1100 - val_loss: 2.3380\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.8885 - val_accuracy: 0.1100 - val_loss: 2.3551\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.7723 - val_accuracy: 0.1100 - val_loss: 2.3539\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.6976 - val_accuracy: 0.1100 - val_loss: 2.3334\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.6479 - val_accuracy: 0.1167 - val_loss: 2.2688\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.5827 - val_accuracy: 0.1500 - val_loss: 2.1859\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.5509 - val_accuracy: 0.2433 - val_loss: 2.0529\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.5053 - val_accuracy: 0.4267 - val_loss: 1.8240\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.4879 - val_accuracy: 0.5367 - val_loss: 1.5531\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8774 - loss: 0.4346 - val_accuracy: 0.6300 - val_loss: 1.2628\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.4363 - val_accuracy: 0.7233 - val_loss: 0.9842\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.4468 - val_accuracy: 0.8200 - val_loss: 0.8068\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.4122 - val_accuracy: 0.8567 - val_loss: 0.5933\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.3682 - val_accuracy: 0.9033 - val_loss: 0.4488\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.3820 - val_accuracy: 0.8900 - val_loss: 0.3978\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.3556 - val_accuracy: 0.8900 - val_loss: 0.3988\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.3348 - val_accuracy: 0.8967 - val_loss: 0.3800\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3372 - val_accuracy: 0.9000 - val_loss: 0.3594\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.3135 - val_accuracy: 0.8833 - val_loss: 0.3496\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.3097 - val_accuracy: 0.9033 - val_loss: 0.2982\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2800 - val_accuracy: 0.8967 - val_loss: 0.3254\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2860 - val_accuracy: 0.9067 - val_loss: 0.3167\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2811 - val_accuracy: 0.9033 - val_loss: 0.2736\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2743 - val_accuracy: 0.9100 - val_loss: 0.3393\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2628 - val_accuracy: 0.9200 - val_loss: 0.2953\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2501 - val_accuracy: 0.9300 - val_loss: 0.2502\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.2503 - val_accuracy: 0.9233 - val_loss: 0.2703\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2509 - val_accuracy: 0.9200 - val_loss: 0.2681\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 3ms/step - accuracy: 0.8922 - loss: 0.3649\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 92.44%\n",
      "🎯 Test Accuracy:     89.22%\n",
      "   Difference:        3.22%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v11.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
