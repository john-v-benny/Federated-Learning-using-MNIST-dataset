{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 9\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part9.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x225ba58a510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3905 - loss: 1.8677 - val_accuracy: 0.1100 - val_loss: 2.2996\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 1.1524 - val_accuracy: 0.1100 - val_loss: 2.2989\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.9075 - val_accuracy: 0.1100 - val_loss: 2.2944\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.8000 - val_accuracy: 0.1100 - val_loss: 2.2835\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.7021 - val_accuracy: 0.1100 - val_loss: 2.2448\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.6266 - val_accuracy: 0.1100 - val_loss: 2.1998\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.5720 - val_accuracy: 0.2067 - val_loss: 2.1225\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.5364 - val_accuracy: 0.3800 - val_loss: 2.0272\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.5047 - val_accuracy: 0.5067 - val_loss: 1.8806\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.4672 - val_accuracy: 0.6533 - val_loss: 1.6840\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.4444 - val_accuracy: 0.7400 - val_loss: 1.4525\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.4239 - val_accuracy: 0.8100 - val_loss: 1.2037\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.4037 - val_accuracy: 0.8500 - val_loss: 0.9127\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.3972 - val_accuracy: 0.8900 - val_loss: 0.6920\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3613 - val_accuracy: 0.8967 - val_loss: 0.5455\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3445 - val_accuracy: 0.8867 - val_loss: 0.4505\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3456 - val_accuracy: 0.8800 - val_loss: 0.4216\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.3357 - val_accuracy: 0.8867 - val_loss: 0.3851\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.3169 - val_accuracy: 0.9100 - val_loss: 0.3579\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3277 - val_accuracy: 0.8633 - val_loss: 0.4065\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.3038 - val_accuracy: 0.8967 - val_loss: 0.3596\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.3021 - val_accuracy: 0.8700 - val_loss: 0.4036\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2911 - val_accuracy: 0.8967 - val_loss: 0.3730\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2733 - val_accuracy: 0.8867 - val_loss: 0.3496\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3088 - val_accuracy: 0.9067 - val_loss: 0.3063\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2604 - val_accuracy: 0.8767 - val_loss: 0.3484\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2725 - val_accuracy: 0.9000 - val_loss: 0.3126\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2595 - val_accuracy: 0.9167 - val_loss: 0.3056\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2563 - val_accuracy: 0.9100 - val_loss: 0.3271\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.2384 - val_accuracy: 0.8800 - val_loss: 0.3840\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.8703 - loss: 0.4548\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.15%\n",
      "🎯 Test Accuracy:     87.03%\n",
      "   Difference:        6.12%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v9.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
