{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 17\n",
    "data_part = np.load(\"..\\mnist_split_data_20\\mnist_part17.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18c61cb0890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3364 - loss: 1.9653 - val_accuracy: 0.0800 - val_loss: 2.3153\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 1.2666 - val_accuracy: 0.0800 - val_loss: 2.3451\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 1.0037 - val_accuracy: 0.0800 - val_loss: 2.3682\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7532 - loss: 0.8349 - val_accuracy: 0.0800 - val_loss: 2.3815\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.7720 - val_accuracy: 0.0800 - val_loss: 2.3583\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.6812 - val_accuracy: 0.0800 - val_loss: 2.3053\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.6292 - val_accuracy: 0.0833 - val_loss: 2.2460\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.5787 - val_accuracy: 0.1100 - val_loss: 2.1018\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.5348 - val_accuracy: 0.2033 - val_loss: 1.9414\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.5191 - val_accuracy: 0.4500 - val_loss: 1.7045\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.4552 - val_accuracy: 0.6233 - val_loss: 1.3945\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.4314 - val_accuracy: 0.7433 - val_loss: 1.1686\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.4119 - val_accuracy: 0.8967 - val_loss: 0.7925\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.4068 - val_accuracy: 0.8600 - val_loss: 0.6631\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3821 - val_accuracy: 0.8533 - val_loss: 0.6438\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.3692 - val_accuracy: 0.8800 - val_loss: 0.4380\n",
      "Epoch 17/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3448 - val_accuracy: 0.8833 - val_loss: 0.3930\n",
      "Epoch 18/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3423 - val_accuracy: 0.8867 - val_loss: 0.3571\n",
      "Epoch 19/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.3156 - val_accuracy: 0.8933 - val_loss: 0.3302\n",
      "Epoch 20/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3253 - val_accuracy: 0.8867 - val_loss: 0.3015\n",
      "Epoch 21/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.3171 - val_accuracy: 0.8900 - val_loss: 0.3816\n",
      "Epoch 22/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2966 - val_accuracy: 0.8433 - val_loss: 0.4538\n",
      "Epoch 23/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2887 - val_accuracy: 0.8633 - val_loss: 0.4055\n",
      "Epoch 24/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2619 - val_accuracy: 0.8733 - val_loss: 0.3388\n",
      "Epoch 25/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2678 - val_accuracy: 0.9067 - val_loss: 0.3227\n",
      "Epoch 26/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2801 - val_accuracy: 0.8833 - val_loss: 0.3877\n",
      "Epoch 27/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2553 - val_accuracy: 0.8800 - val_loss: 0.3607\n",
      "Epoch 28/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2620 - val_accuracy: 0.8933 - val_loss: 0.3373\n",
      "Epoch 29/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.2475 - val_accuracy: 0.8967 - val_loss: 0.3451\n",
      "Epoch 30/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2479 - val_accuracy: 0.8933 - val_loss: 0.3362\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b04141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "16/16 - 0s - 2ms/step - accuracy: 0.8962 - loss: 0.3226\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 92.29%\n",
      "🎯 Test Accuracy:     89.62%\n",
      "   Difference:        2.67%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v17.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
