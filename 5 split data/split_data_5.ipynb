{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9663583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97133c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Original training data shape: (60000, 28, 28)\n",
      "Original training labels shape: (60000,)\n",
      "Original test data shape: (10000, 28, 28)\n",
      "Original test labels shape: (10000,)\n",
      "Data type: uint8\n",
      "Pixel value range: [0, 255]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Original training data shape: {x_train.shape}\")\n",
    "print(f\"Original training labels shape: {y_train.shape}\")\n",
    "print(f\"Original test data shape: {x_test.shape}\")\n",
    "print(f\"Original test labels shape: {y_test.shape}\")\n",
    "print(f\"Data type: {x_train.dtype}\")\n",
    "print(f\"Pixel value range: [{x_train.min()}, {x_train.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996df80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1] range\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35166524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (70000, 28, 28)\n",
      "Combined labels shape: (70000,)\n",
      "Data shuffled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Combine training and test data for balanced splitting\n",
    "x_combined = np.concatenate([x_train_norm, x_test_norm], axis=0)\n",
    "y_combined = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "print(f\"Combined data shape: {x_combined.shape}\")\n",
    "print(f\"Combined labels shape: {y_combined.shape}\")\n",
    "\n",
    "# Shuffle the combined data\n",
    "from sklearn.utils import shuffle\n",
    "x_combined, y_combined = shuffle(x_combined, y_combined, random_state=42)\n",
    "print(\"Data shuffled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdba637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 total samples: 14000\n",
      "Part 2 total samples: 14000\n",
      "Part 3 total samples: 14000\n",
      "Part 4 total samples: 14000\n",
      "Part 5 total samples: 14000\n",
      "Covered: 70000 of 70000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Five equal, disjoint, stratified parts\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "parts_x, parts_y, fold_indices = [], [], []\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(x_combined, y_combined), start=1):\n",
    "    parts_x.append(x_combined[test_idx])\n",
    "    parts_y.append(y_combined[test_idx])\n",
    "    fold_indices.append(test_idx)\n",
    "    print(f\"Part {fold} total samples: {parts_x[-1].shape[0]}\")\n",
    "\n",
    "# Optional: assign to named variables if you prefer\n",
    "x_part1_all, y_part1_all = parts_x[0], parts_y[0]\n",
    "x_part2_all, y_part2_all = parts_x[1], parts_y[1]\n",
    "x_part3_all, y_part3_all = parts_x[2], parts_y[2]\n",
    "x_part4_all, y_part4_all = parts_x[3], parts_y[3]\n",
    "x_part5_all, y_part5_all = parts_x[4], parts_y[4]\n",
    "\n",
    "# Sanity check (coverage and no overlap)\n",
    "concat_idx = np.concatenate(fold_indices)\n",
    "print(f\"Covered: {np.unique(concat_idx).size} of {x_combined.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4d7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: train=11999, test=2001\n",
      "Part 2: train=11999, test=2001\n",
      "Part 3: train=11999, test=2001\n",
      "Part 4: train=11999, test=2001\n",
      "Part 5: train=11999, test=2001\n"
     ]
    }
   ],
   "source": [
    "original_train_ratio = 60000 / (60000 + 10000)\n",
    "test_ratio = 1 - original_train_ratio  # ~0.142857\n",
    "\n",
    "x_parts_train, x_parts_test, y_parts_train, y_parts_test = [], [], [], []\n",
    "\n",
    "for i, (px, py) in enumerate(zip(parts_x, parts_y), start=1):\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "        px, py,\n",
    "        test_size=test_ratio,\n",
    "        stratify=py,\n",
    "        random_state=42  # keep reproducible\n",
    "    )\n",
    "    x_parts_train.append(x_tr); x_parts_test.append(x_te)\n",
    "    y_parts_train.append(y_tr); y_parts_test.append(y_te)\n",
    "    print(f\"Part {i}: train={x_tr.shape[0]}, test={x_te.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d90784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Part 1 to mnist_split_data_5\\mnist_part1.npz (3.51 MB)\n",
      "Saved Part 2 to mnist_split_data_5\\mnist_part2.npz (3.52 MB)\n",
      "Saved Part 3 to mnist_split_data_5\\mnist_part3.npz (3.52 MB)\n",
      "Saved Part 4 to mnist_split_data_5\\mnist_part4.npz (3.52 MB)\n",
      "Saved Part 5 to mnist_split_data_5\\mnist_part5.npz (3.51 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = \"mnist_split_data_5\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i in range(5):\n",
    "    out_path = os.path.join(save_dir, f\"mnist_part{i+1}.npz\")\n",
    "    np.savez_compressed(\n",
    "        out_path,\n",
    "        x_train=x_parts_train[i],\n",
    "        y_train=y_parts_train[i],\n",
    "        x_test=x_parts_test[i],\n",
    "        y_test=y_parts_test[i],\n",
    "    )\n",
    "    size_mb = os.path.getsize(out_path) / (1024*1024)\n",
    "    print(f\"Saved Part {i+1} to {out_path} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5031be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
