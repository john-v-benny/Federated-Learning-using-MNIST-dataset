{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa58e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "922fa751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Train shape = (11999, 28, 28), Test shape = (2001, 28, 28)\n",
      "Part 2: Train shape = (11999, 28, 28), Test shape = (2001, 28, 28)\n",
      "Part 3: Train shape = (11999, 28, 28), Test shape = (2001, 28, 28)\n",
      "Part 4: Train shape = (11999, 28, 28), Test shape = (2001, 28, 28)\n",
      "Part 5: Train shape = (11999, 28, 28), Test shape = (2001, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load all 5 split data files\n",
    "train_data_list = []\n",
    "train_labels_list = []\n",
    "test_data_list = []\n",
    "test_labels_list = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    data = np.load(f\"./data/5_split_data/mnist_part{i}.npz\")\n",
    "    train_data_list.append(data['x_train'])\n",
    "    train_labels_list.append(data['y_train'])\n",
    "    test_data_list.append(data['x_test'])\n",
    "    test_labels_list.append(data['y_test'])\n",
    "    print(f\"Part {i}: Train shape = {data['x_train'].shape}, Test shape = {data['x_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773ae426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 59995\n",
      "Total training labels: 59995\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all training data\n",
    "all_train_data = np.concatenate(train_data_list, axis=0)\n",
    "all_train_labels = np.concatenate(train_labels_list, axis=0)\n",
    "\n",
    "print(f\"Total training samples: {all_train_data.shape[0]}\")\n",
    "print(f\"Total training labels: {all_train_labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6bd9281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shuffled!\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the training data\n",
    "indices = np.random.permutation(len(all_train_data))\n",
    "shuffled_train_data = all_train_data[indices]\n",
    "shuffled_train_labels = all_train_labels[indices]\n",
    "\n",
    "print(\"Training data shuffled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a38be41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: 11999 training samples\n",
      "Client 2: 11999 training samples\n",
      "Client 3: 11999 training samples\n",
      "Client 4: 11999 training samples\n",
      "Client 5: 11999 training samples\n"
     ]
    }
   ],
   "source": [
    "# Split the shuffled data back into 5 equal parts\n",
    "samples_per_client = len(shuffled_train_data) // 5\n",
    "\n",
    "new_train_data = []\n",
    "new_train_labels = []\n",
    "\n",
    "for i in range(5):\n",
    "    start_idx = i * samples_per_client\n",
    "    if i == 4:  # Last client gets remaining samples\n",
    "        end_idx = len(shuffled_train_data)\n",
    "    else:\n",
    "        end_idx = (i + 1) * samples_per_client\n",
    "    \n",
    "    new_train_data.append(shuffled_train_data[start_idx:end_idx])\n",
    "    new_train_labels.append(shuffled_train_labels[start_idx:end_idx])\n",
    "    print(f\"Client {i+1}: {new_train_data[i].shape[0]} training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f344b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: data/5_split_shuffled4\n"
     ]
    }
   ],
   "source": [
    "# Create directory for shuffled data\n",
    "output_dir = 'data/5_split_shuffled4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Created directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a107df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved shuffled mnist_part1.npz\n",
      "Saved shuffled mnist_part2.npz\n",
      "Saved shuffled mnist_part3.npz\n",
      "Saved shuffled mnist_part4.npz\n",
      "Saved shuffled mnist_part5.npz\n",
      "\n",
      "All files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save each part with shuffled training data and original test data\n",
    "for i in range(5):\n",
    "    np.savez(\n",
    "        f'{output_dir}/mnist_part{i+1}.npz',\n",
    "        x_train=new_train_data[i],\n",
    "        y_train=new_train_labels[i],\n",
    "        x_test=test_data_list[i],  # Keep original test data\n",
    "        y_test=test_labels_list[i]  # Keep original test labels\n",
    "    )\n",
    "    print(f\"Saved shuffled mnist_part{i+1}.npz\")\n",
    "\n",
    "print(\"\\nAll files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa0d3361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification:\n",
      "Part 1 - Train: (11999, 28, 28), Test: (2001, 28, 28)\n",
      "First 10 training labels: [1 5 5 0 3 5 1 7 4 8]\n",
      "First 10 test labels: [3 1 1 2 9 8 6 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "# Verify by loading and checking one file\n",
    "verify_data = np.load(f'{output_dir}/mnist_part1.npz')\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"Part 1 - Train: {verify_data['x_train'].shape}, Test: {verify_data['x_test'].shape}\")\n",
    "print(f\"First 10 training labels: {verify_data['y_train'][:10]}\")\n",
    "print(f\"First 10 test labels: {verify_data['y_test'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645eaa35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
