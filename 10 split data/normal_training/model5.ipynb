{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 5\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part5.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2393bef3150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4771 - loss: 1.5646 - val_accuracy: 0.0883 - val_loss: 2.3343\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7103 - loss: 0.9322 - val_accuracy: 0.0883 - val_loss: 2.4116\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.7160 - val_accuracy: 0.0883 - val_loss: 2.4224\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.6131 - val_accuracy: 0.1067 - val_loss: 2.2228\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8461 - loss: 0.5364 - val_accuracy: 0.3133 - val_loss: 1.8233\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.4801 - val_accuracy: 0.7067 - val_loss: 1.2018\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.4495 - val_accuracy: 0.8700 - val_loss: 0.6444\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.4217 - val_accuracy: 0.8983 - val_loss: 0.4053\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3798 - val_accuracy: 0.8900 - val_loss: 0.3578\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.3610 - val_accuracy: 0.9000 - val_loss: 0.3551\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3470 - val_accuracy: 0.8983 - val_loss: 0.3121\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.3283 - val_accuracy: 0.8950 - val_loss: 0.3321\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.3151 - val_accuracy: 0.9117 - val_loss: 0.2991\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.3006 - val_accuracy: 0.9117 - val_loss: 0.3031\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2820 - val_accuracy: 0.9050 - val_loss: 0.3246\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2975 - val_accuracy: 0.9117 - val_loss: 0.3186\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2713 - val_accuracy: 0.9100 - val_loss: 0.3276\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2670 - val_accuracy: 0.9100 - val_loss: 0.2861\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2665 - val_accuracy: 0.9033 - val_loss: 0.3051\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2529 - val_accuracy: 0.9150 - val_loss: 0.3025\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2479 - val_accuracy: 0.9167 - val_loss: 0.2923\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2325 - val_accuracy: 0.9133 - val_loss: 0.2986\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2375 - val_accuracy: 0.9133 - val_loss: 0.3276\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2286 - val_accuracy: 0.8983 - val_loss: 0.3613\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2166 - val_accuracy: 0.9167 - val_loss: 0.2953\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2211 - val_accuracy: 0.9167 - val_loss: 0.3007\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2008 - val_accuracy: 0.9233 - val_loss: 0.2797\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1965 - val_accuracy: 0.9167 - val_loss: 0.2882\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.1874 - val_accuracy: 0.9117 - val_loss: 0.2896\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.2046 - val_accuracy: 0.9217 - val_loss: 0.2881\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 2ms/step - accuracy: 0.9301 - loss: 0.2803\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.70%\n",
      "🎯 Test Accuracy:     93.01%\n",
      "   Difference:        0.70%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v5.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
