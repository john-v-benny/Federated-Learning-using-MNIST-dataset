{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 4\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part4.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1876aa6ad10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4788 - loss: 1.5767 - val_accuracy: 0.1200 - val_loss: 2.3292\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.8948 - val_accuracy: 0.1200 - val_loss: 2.3748\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.6993 - val_accuracy: 0.1633 - val_loss: 2.3231\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.6124 - val_accuracy: 0.1817 - val_loss: 2.1209\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.5332 - val_accuracy: 0.3117 - val_loss: 1.7433\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.4849 - val_accuracy: 0.7550 - val_loss: 1.1973\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.4576 - val_accuracy: 0.8367 - val_loss: 0.7199\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.4296 - val_accuracy: 0.8567 - val_loss: 0.4927\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.4036 - val_accuracy: 0.9033 - val_loss: 0.3390\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8911 - loss: 0.3754 - val_accuracy: 0.9167 - val_loss: 0.3094\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3581 - val_accuracy: 0.8967 - val_loss: 0.3274\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.3417 - val_accuracy: 0.9017 - val_loss: 0.3018\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.3232 - val_accuracy: 0.9100 - val_loss: 0.3036\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.3144 - val_accuracy: 0.9033 - val_loss: 0.2992\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2940 - val_accuracy: 0.9100 - val_loss: 0.2871\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2952 - val_accuracy: 0.8983 - val_loss: 0.3141\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2824 - val_accuracy: 0.9050 - val_loss: 0.3116\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2803 - val_accuracy: 0.9100 - val_loss: 0.3068\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2581 - val_accuracy: 0.9083 - val_loss: 0.3007\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2581 - val_accuracy: 0.9133 - val_loss: 0.2805\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2400 - val_accuracy: 0.9050 - val_loss: 0.2926\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2552 - val_accuracy: 0.9083 - val_loss: 0.3093\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.2462 - val_accuracy: 0.8933 - val_loss: 0.3327\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.2491 - val_accuracy: 0.9150 - val_loss: 0.2791\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2310 - val_accuracy: 0.9033 - val_loss: 0.2989\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.2084 - val_accuracy: 0.9267 - val_loss: 0.2398\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2114 - val_accuracy: 0.9300 - val_loss: 0.2510\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.2126 - val_accuracy: 0.9217 - val_loss: 0.2563\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.2151 - val_accuracy: 0.9233 - val_loss: 0.2723\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.2093 - val_accuracy: 0.9167 - val_loss: 0.2784\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 1ms/step - accuracy: 0.9251 - loss: 0.2510\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.70%\n",
      "🎯 Test Accuracy:     92.51%\n",
      "   Difference:        1.20%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v4.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
