{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 10\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part10.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x205856aaa50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4488 - loss: 1.6830 - val_accuracy: 0.0950 - val_loss: 2.3415\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 1.0059 - val_accuracy: 0.1450 - val_loss: 2.3894\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7650 - loss: 0.7877 - val_accuracy: 0.1317 - val_loss: 2.3729\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.6598 - val_accuracy: 0.1467 - val_loss: 2.1865\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.5824 - val_accuracy: 0.1633 - val_loss: 1.8845\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.5292 - val_accuracy: 0.6767 - val_loss: 1.2672\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4950 - val_accuracy: 0.8817 - val_loss: 0.7253\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.4403 - val_accuracy: 0.8817 - val_loss: 0.5001\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.4368 - val_accuracy: 0.8967 - val_loss: 0.3775\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.4073 - val_accuracy: 0.8867 - val_loss: 0.3617\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.3838 - val_accuracy: 0.8833 - val_loss: 0.3879\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3735 - val_accuracy: 0.9050 - val_loss: 0.3365\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.3503 - val_accuracy: 0.8683 - val_loss: 0.4062\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9011 - loss: 0.3304 - val_accuracy: 0.8933 - val_loss: 0.3524\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.3349 - val_accuracy: 0.8767 - val_loss: 0.4325\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.3103 - val_accuracy: 0.9000 - val_loss: 0.3594\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.3109 - val_accuracy: 0.9033 - val_loss: 0.3377\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.3121 - val_accuracy: 0.8867 - val_loss: 0.3933\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2827 - val_accuracy: 0.8983 - val_loss: 0.3519\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.2849 - val_accuracy: 0.9150 - val_loss: 0.3175\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2717 - val_accuracy: 0.9017 - val_loss: 0.3444\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2718 - val_accuracy: 0.9067 - val_loss: 0.3357\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2720 - val_accuracy: 0.9050 - val_loss: 0.3335\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2662 - val_accuracy: 0.9133 - val_loss: 0.3405\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2403 - val_accuracy: 0.9167 - val_loss: 0.3222\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2531 - val_accuracy: 0.9167 - val_loss: 0.3022\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2503 - val_accuracy: 0.9150 - val_loss: 0.3263\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2431 - val_accuracy: 0.9067 - val_loss: 0.3255\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2391 - val_accuracy: 0.9117 - val_loss: 0.3091\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2267 - val_accuracy: 0.9050 - val_loss: 0.3331\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 1ms/step - accuracy: 0.9261 - loss: 0.2559\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 92.96%\n",
      "🎯 Test Accuracy:     92.61%\n",
      "   Difference:        0.35%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v10.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
