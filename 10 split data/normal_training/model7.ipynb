{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 7\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part7.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202f11289d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4547 - loss: 1.6888 - val_accuracy: 0.1200 - val_loss: 2.3325\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 1.0111 - val_accuracy: 0.1083 - val_loss: 2.3880\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.7917 - val_accuracy: 0.1083 - val_loss: 2.3632\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.6709 - val_accuracy: 0.1083 - val_loss: 2.1839\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.5916 - val_accuracy: 0.1650 - val_loss: 1.9063\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.5240 - val_accuracy: 0.5900 - val_loss: 1.3008\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.4826 - val_accuracy: 0.8533 - val_loss: 0.7084\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.4568 - val_accuracy: 0.8983 - val_loss: 0.4411\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.4158 - val_accuracy: 0.9050 - val_loss: 0.3523\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3859 - val_accuracy: 0.8967 - val_loss: 0.3493\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3765 - val_accuracy: 0.9083 - val_loss: 0.3049\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.3512 - val_accuracy: 0.9100 - val_loss: 0.2986\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.3400 - val_accuracy: 0.9167 - val_loss: 0.2874\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - loss: 0.3458 - val_accuracy: 0.9217 - val_loss: 0.2827\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.3076 - val_accuracy: 0.9017 - val_loss: 0.3101\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.3035 - val_accuracy: 0.9033 - val_loss: 0.3373\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2936 - val_accuracy: 0.9300 - val_loss: 0.2605\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2875 - val_accuracy: 0.9083 - val_loss: 0.3134\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2875 - val_accuracy: 0.9117 - val_loss: 0.2894\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2668 - val_accuracy: 0.9233 - val_loss: 0.2821\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2558 - val_accuracy: 0.9183 - val_loss: 0.2765\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2520 - val_accuracy: 0.9033 - val_loss: 0.3055\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2474 - val_accuracy: 0.9083 - val_loss: 0.3026\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2492 - val_accuracy: 0.9183 - val_loss: 0.2857\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2452 - val_accuracy: 0.9250 - val_loss: 0.2697\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2319 - val_accuracy: 0.9217 - val_loss: 0.2798\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.2209 - val_accuracy: 0.9383 - val_loss: 0.2581\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.2237 - val_accuracy: 0.9267 - val_loss: 0.2710\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2003 - val_accuracy: 0.9100 - val_loss: 0.2957\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1978 - val_accuracy: 0.9233 - val_loss: 0.2612\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 2ms/step - accuracy: 0.9161 - loss: 0.2958\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 94.07%\n",
      "🎯 Test Accuracy:     91.61%\n",
      "   Difference:        2.46%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v7.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
