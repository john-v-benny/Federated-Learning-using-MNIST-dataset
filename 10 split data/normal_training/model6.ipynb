{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 6\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part6.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c8cd0b790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4690 - loss: 1.5835 - val_accuracy: 0.2500 - val_loss: 2.3148\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.9158 - val_accuracy: 0.0883 - val_loss: 2.3250\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.7353 - val_accuracy: 0.0883 - val_loss: 2.2786\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.6142 - val_accuracy: 0.1017 - val_loss: 2.1281\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.5407 - val_accuracy: 0.3050 - val_loss: 1.8133\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.4957 - val_accuracy: 0.7167 - val_loss: 1.2304\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.4545 - val_accuracy: 0.8333 - val_loss: 0.7652\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.4446 - val_accuracy: 0.8950 - val_loss: 0.4333\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.4019 - val_accuracy: 0.8917 - val_loss: 0.3658\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3859 - val_accuracy: 0.8983 - val_loss: 0.3427\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3593 - val_accuracy: 0.9100 - val_loss: 0.3250\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3742 - val_accuracy: 0.8900 - val_loss: 0.3354\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.3470 - val_accuracy: 0.9083 - val_loss: 0.3084\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3401 - val_accuracy: 0.9067 - val_loss: 0.3336\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.3203 - val_accuracy: 0.8950 - val_loss: 0.3377\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.3120 - val_accuracy: 0.8917 - val_loss: 0.3328\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.3204 - val_accuracy: 0.9183 - val_loss: 0.3035\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2912 - val_accuracy: 0.9050 - val_loss: 0.3103\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2805 - val_accuracy: 0.9017 - val_loss: 0.3023\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2804 - val_accuracy: 0.9033 - val_loss: 0.3437\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2895 - val_accuracy: 0.8950 - val_loss: 0.3307\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2766 - val_accuracy: 0.8833 - val_loss: 0.3683\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2565 - val_accuracy: 0.9200 - val_loss: 0.2875\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2653 - val_accuracy: 0.9150 - val_loss: 0.2848\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2507 - val_accuracy: 0.9200 - val_loss: 0.2856\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2413 - val_accuracy: 0.9283 - val_loss: 0.2614\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2427 - val_accuracy: 0.9050 - val_loss: 0.3211\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2346 - val_accuracy: 0.9050 - val_loss: 0.3109\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2466 - val_accuracy: 0.9200 - val_loss: 0.3027\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.2335 - val_accuracy: 0.9117 - val_loss: 0.3073\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 1ms/step - accuracy: 0.9141 - loss: 0.2768\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 92.46%\n",
      "🎯 Test Accuracy:     91.41%\n",
      "   Difference:        1.05%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v6.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
