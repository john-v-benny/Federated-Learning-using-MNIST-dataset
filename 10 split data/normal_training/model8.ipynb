{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc90e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part 8\n",
    "data_part = np.load(\"..\\mnist_split_data_10\\mnist_part8.npz\")\n",
    "x_train = data_part['x_train']\n",
    "y_train = data_part['y_train']\n",
    "x_test = data_part['x_test']\n",
    "y_test = data_part['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ced8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd91dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x243d8dbb710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\amrita intern\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,042</span> (437.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,042\u001b[0m (437.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,594</span> (435.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,594\u001b[0m (435.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4812 - loss: 1.5919 - val_accuracy: 0.0650 - val_loss: 2.3497\n",
      "Epoch 2/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7099 - loss: 0.9461 - val_accuracy: 0.0650 - val_loss: 2.4129\n",
      "Epoch 3/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.7556 - val_accuracy: 0.0733 - val_loss: 2.3315\n",
      "Epoch 4/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.6296 - val_accuracy: 0.1750 - val_loss: 2.1130\n",
      "Epoch 5/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.5485 - val_accuracy: 0.4900 - val_loss: 1.6554\n",
      "Epoch 6/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.5015 - val_accuracy: 0.7933 - val_loss: 1.1498\n",
      "Epoch 7/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.4632 - val_accuracy: 0.8783 - val_loss: 0.6511\n",
      "Epoch 8/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.4172 - val_accuracy: 0.8967 - val_loss: 0.4631\n",
      "Epoch 9/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.4036 - val_accuracy: 0.9200 - val_loss: 0.2776\n",
      "Epoch 10/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.3737 - val_accuracy: 0.9317 - val_loss: 0.2526\n",
      "Epoch 11/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.3544 - val_accuracy: 0.9133 - val_loss: 0.2554\n",
      "Epoch 12/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.3426 - val_accuracy: 0.9267 - val_loss: 0.2334\n",
      "Epoch 13/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3284 - val_accuracy: 0.9150 - val_loss: 0.2629\n",
      "Epoch 14/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3161 - val_accuracy: 0.9100 - val_loss: 0.2617\n",
      "Epoch 15/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2942 - val_accuracy: 0.9150 - val_loss: 0.2926\n",
      "Epoch 16/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2947 - val_accuracy: 0.9283 - val_loss: 0.2202\n",
      "Epoch 17/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2908 - val_accuracy: 0.9033 - val_loss: 0.2890\n",
      "Epoch 18/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2729 - val_accuracy: 0.8950 - val_loss: 0.3032\n",
      "Epoch 19/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2819 - val_accuracy: 0.9317 - val_loss: 0.2078\n",
      "Epoch 20/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2689 - val_accuracy: 0.9350 - val_loss: 0.1976\n",
      "Epoch 21/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2454 - val_accuracy: 0.9333 - val_loss: 0.1980\n",
      "Epoch 22/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.2469 - val_accuracy: 0.9333 - val_loss: 0.1898\n",
      "Epoch 23/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2560 - val_accuracy: 0.9350 - val_loss: 0.2127\n",
      "Epoch 24/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2332 - val_accuracy: 0.9417 - val_loss: 0.1745\n",
      "Epoch 25/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.2254 - val_accuracy: 0.9433 - val_loss: 0.1848\n",
      "Epoch 26/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.2216 - val_accuracy: 0.9400 - val_loss: 0.2175\n",
      "Epoch 27/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2131 - val_accuracy: 0.9417 - val_loss: 0.2073\n",
      "Epoch 28/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2145 - val_accuracy: 0.9250 - val_loss: 0.2521\n",
      "Epoch 29/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.2048 - val_accuracy: 0.9417 - val_loss: 0.2002\n",
      "Epoch 30/30\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2070 - val_accuracy: 0.9367 - val_loss: 0.1931\n"
     ]
    }
   ],
   "source": [
    "# Improved Model with Multiple Hidden Layers and Optimizations\n",
    "model = keras.Sequential([\n",
    "    # First hidden layer - Feature extraction\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    \n",
    "    # Second hidden layer - Pattern recognition\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Third hidden layer - Feature refinement\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    \n",
    "    # Output layer - Classification\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Changed to softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile with optimized parameters\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Optimized learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train with improved parameters\n",
    "history = model.fit(\n",
    "    x_train_flatten, y_train,\n",
    "    epochs=30,           # More epochs for better learning\n",
    "    batch_size=64,      # Optimal batch size\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cdadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "32/32 - 0s - 2ms/step - accuracy: 0.9261 - loss: 0.2814\n",
      "\n",
      "============================================================\n",
      "🎯 Training Accuracy: 93.48%\n",
      "🎯 Test Accuracy:     92.61%\n",
      "   Difference:        0.87%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flatten, y_test, verbose=2)\n",
    "\n",
    "# Get final training accuracy from history\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🎯 Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"🎯 Test Accuracy:     {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Difference:        {abs(train_accuracy - test_accuracy) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('..\\saved_models\\mnist_model_v8.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc96d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
